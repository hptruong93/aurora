Dec 10:   

    $ sudo apt-get update; sudo apt-get upgrade
    $ sudo apt-get install python-dev python-pip build-essential libmysqlclient-dev
    $ sudo pip install pika
    $ sudo pip install psutil paste requests
    $ sudo easy_install -U distribute
    $ sudo pip install mysql-python
    
download python-ifconfig from
https://code.google.com/p/python-ifconfig/downloads/detail?name=python-ifconfig-0.1.tar.gz&can=2&q=
    $ sudo python setup.py install
    
To run Send.py, need RabbitMQ
    $ sudo apt-get install rabbitmq-server


Should be able to list slices based on wnet
-   associate a slice
-   disassociate a slice
(others follow)


Dec 11:

parse a config file with a wnet command.
determine which ap slices are included in this wnet (from database)
assume they use capsulator to send their messages to their tenant
associating a slice with a wnet? --update database
disassociating a slice from a wnet?  --update database
changing gateway of slices? --update capsulator data
adding tags to ap in wnet? --update database?

MySQL setup: http://draalin.com/installing-lamp-in-ubuntu/
    $ sudo apt-get install lamp-server^ 
    
phpMyAdmin setup: https://www.digitalocean.com/community/articles/how-to-install-and-secure-phpmyadmin-on-ubuntu-12-04
    $ sudo apt-get install phpmyadmin
    
credentials for phpMyAdmin: http://localhost/phpmyadmin
user1   secret
root    supersecret

can use SQLdb_create.py in manager to make tables, and sql_check.py to update them to match existing files  
    
    
in building sql database (sql_check), required items missing from apslice-* files? (syncAPSlice())
    also table name is ap, not access_point, which should it be?
    
aurora_console.py only parses, doesn't run anything.  when complete, what should it launch?
    edit: console is deprecated, was testing for client shell
project_id is in MySQL database but not supported throughout all modules?
what are location_tags and tenant_tags for?

see example ap-slice1.json, this is generated by the manager and sent by RabbitMQ to 
the relevant APs    use this file format to modify data on AP, but can only modify things in
VirtualBridges, not in VirtualInterfaces

to run, start ap_provision.py, which hosts HTTP server for AP to get RabbitMQ queue from
Need to put things in 'ap' folder on a machine running OpenWRT
in order to use command 'wifi down' etc.

TODO: Get OpenWRT running on VirtualBox
TODO: run Receive.py on OpenWRT
TODO: determine how command 'wifi down' works
TODO: determine how Open vSwitch works

Dec 12:

Could instead comment out code in Receive.py which actually does wifi manipulation
OpenWRT on VirtualBox: http://wiki.openwrt.org/doc/howto/virtualbox

In ap/ovs.py, modify_bridge() is allowed, can change IP address and controller
of OVS in question.  Can not modify port settings for now (ask Michael)

Installing OVS: Download from http://openvswitch.org/download
In root openvswitch directory:
    $ ./configure
    $ sudo make
    $ sudo make check
    $ su
    $ make install
    $ mkdir -p /usr/local/etc/openvswitch
    
To run: 
    $ ovsdb-tool create /usr/local/etc/openvswitch/conf.db vswitchd/vswitch.ovsschema
    $ ovsdb-server --remote=punix:/usr/local/var/run/openvswitch/db.sock \
                   --remote=db:Open_vSwitch,Open_vSwitch,manager_options \
                   --private-key=db:Open_vSwitch,SSL,private_key \
                   --certificate=db:Open_vSwitch,SSL,certificate \
                   --bootstrap-ca-cert=db:Open_vSwitch,SSL,ca_cert \
                   --pidfile --detach
    $ ovs-vsctl --no-wait init
    $ ovs-vswitchd --pidfile --detach 
    
Now can make new bridges:
    $ ovs-vsctl add-br br0
    $ ovs-vsctl add-port br0 eth0
    $ ovs-vsctl add-port br0 vif1.0
    $ ovs-vsctl del-br br0
    
manager/dispatcher.py replaces Send.py 
SQL database is main database
Manager().ap_slice_modify() modifies non-hardware related params
can change tags ap_slice_add_tag(), ap_slice_remove_tag()

mysql:
    $ mysql --user root -p
    > use aurora #switches databases
    > show tables;
    > SELECT * FROM ap_slice;
    > SELECT tenant_id FROM ap_slice WHERE ap_slice_id=1;
    > SELECT tenant_id FROM ap_slice;
    > INSERT into ap_slice VALUES ('5', '1', [etc])
    > DELETE from ap_slice WHERE physical_ap='openflow'
    > DESCRIBE ap_slice
    > JOIN (?later?)
    not symbol is <>
    
some functionality in wnet supported in database, but no delete all, or tenant-added
tag to all slices in a wnet
    
To add a console commands modify auroraclient/json/shell.json
Add a handler in manager to receive function and params.
(Can make new file, import manager to test)

keystone required for auroraclient/shell.py
to install openstack:
    $ sudo apt-get install git
    $ git clone git://github.com/openstack-dev/devstack.git
    $ cd devstack; ./stack.sh
(all passwd set to 'supersecret')
(error thrown, didn't continue.. for now, just commented auth part 
of auroraclient/shell.py)
    
Can set up tunneling with OVS, how can I use this to change gateway for multiple
ap slices?

Implement wnet_delete_all:
- client will build a file based on command to auroraclient shell
  python shell.py wnet-remove-all-wslices <wnet-name ...>
- client sends built file using auroraclient/SendJSON.py (if I have a file
  already, can change which file is sent here)
- sent file is received by ManagerServer.py, which must be running before
  sending JSON
- 

(note: ctrl+z pauses a task, can list it with 'jobs', and select with 'fg')
(append a terminal command with & to run in background)

Noticed SQLdb_create.py makes location_tags with column ap_slice_id, where
manager expects ap_name

--> Added wnet-remove-all-wslices to auroraclient/json/shell.json
--> Modified clientserver.py, SendJSON.py to get rid of threading errors

auroraclient/shell.py arguments are in wrong order upon help message display

Managed to get a wnet-remove-all-wslices communicating with MySQL and identifying
correct ap_slice instances

Dec 13:

--> Added basic errorhandling (ConnectionError) in SendJSON.py
--> Changed aurora_db.py wnet_remove_slice to use ap_slice_id (it was ap_slice_timesid
    which didn't make sense?)
--> Finished wnet_remove_all_wslices() in manager.py
--> Added _wnet_show_wslices helper method to manager.py
--> Added wnet_show_wslices to manager.py
--> Added wnet-show-wslices to auroraclient/json/shell.json
--> Added wnet-add-tag-to-wslices to auroraclient/json/shell.json
--> Added wnet_add_tag_to_wslices to manager.py
--> aurora_db.py method slice_add, typo (INSERT), it also needs quotes around strings
--> Added wnet-rem-tag-from-wslices to auroraclient/json/shell.json
--> Added wnet_rem_tag_from_wslices to manager.py

TODO:
For slices that don't belong to tenant requesting wnet-add-wslice, deny
Implement message passing to state denied request for non-existant slice
For gateway, command should be something like wnet-join-subnet
When deleting a wnet, change associated ap_slices to wnet = Null
wnet-show should list details of wnet as well as associated slices
In wnet-rem-tag exception for nonexistant tag
Change names to wnet-add-tag, wnet-remove-tag

Serial connection to AP
(COM3?) Speed 38400
nano /etc/config/network
Google openwrt network configuration

--> Made it possible to type auroraclient or aurora on command line
    To do this, make a python script that points to auroraclient/shell.py called
    auroraclient, and have it pass along any command line arguments.
    Place auroraclient launch script in /usr/local/bin, and chmod +x.
    Add #!/usr/bin/python at the top, check /usr/local/bin is in $PATH
    use command gnome-terminal -x <command> to launch a new terminal window
    (ls -l to show file permissions)
    Note: Could have just created a symlink...

Dec 16:

Open vSwitch Research: L2GRE tunnel
https://www.youtube.com/watch?v=VMP4Q2XtFjw
http://networkstatic.net/open-vswitch-gre-tunnel-configuration/

With OVS Tunnel, use veth instead of capsulator
Install QEMU to have greater control over tunnel between vms and clients
Ubuntu1 Open vSwitch Practice VM:
    $ sudo apt-get install git
    $ mkdir ~/QEMU; cd ~/QEMU
    $ git clone git://git.qemu-project.org/qemu.git
    
Scratch that.  To install qemu:
    $ sudo apt-get install qemu kvm
    $ qemu-img create ubuntu-test 3G
    $ qemu-system-x86_64 -hda ubuntu-test \
        -cdrom raw_linux_image/ubuntu-12.04.3-desktop-amd64.iso \
        -m 256 -boot d
    $ qemu-system-i386 -hda ubuntu-test \
        -cdrom ubuntu-12.04.3-desktop-i386.iso \
        -m 256 -b
    
To test: Nest virtual machines http://kashyapc.wordpress.com/2012/01/14/nested-virtualization-with-kvm-intel/
(Didn't work...)
http://networkstatic.net/openflow-openvswitch-and-kvm-sdn-lab-installation-app/

On VM Ubuntu OpenvSwitch Practice2:
    $ mkdir ~/ovs_testing; cd ~/ovs_testing
    $ wget http://dl.dropbox.com/u/43333687/sdn.lab.install.v1.2.py
    $ sudo python sdn.lab.install.v1.2.py
Install package 1, this sets up ovs with a local controller, and creates / launches a vm
in qemu in order to test different networking layouts (tunneling)

Trying again, ggaaah: http://networkstatic.net/openflow-openvswitch-lab/

    $ sudo nano /etc/network/interfaces

auto eth0
iface eth0 inet static
        address 10.0.2.15
        netmask 255.255.255.0
        network 10.0.2.0
        broadcast 10.0.2.255
        dns-nameservers 8.8.8.8
        gateway 10.0.2.2

    $ /etc/init.d/networking restart        


#############################################################

Nope, trying again:
    $ sudo apt-get install -y git kvm qemu-kvm openvswitch-controller uml-utilities\
    $ sudo apt-get install openvswitch-switch openvswitch-common
    
This seems to work (so far), verified by:
    $ sudo ovs-vsctl show
    $ ps -ea |grep ovs
    $ sudo /etc/init.d/openvswitch-switch restart
    
Become root:   
    $ ovs-vsctl add-br br-int
    $ ovs-vsctl add-port br-int eth0
    
Zero out your eth0 interface and slap its previous ip on the bridge interface
(warning will clip you unless you script it)  
    $ ifconfig eth0 0
    $ ifconfig br-int 10.0.2.15 netmask 255.255.255.0
    
Change your default route
    $ route add default gw 10.0.2.2 br-int
    $ route del default gw 10.0.2.2 eth0
    
Make sure routing table checks out
    $ route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         10.0.2.2        0.0.0.0         UG    0      0        0 br-int
10.0.2.0        0.0.0.0         255.255.255.0   U     0      0        0 br-int

    $ ifconfig
br-int    Link encap:Ethernet  HWaddr 08:00:27:7c:a2:07  
          inet addr:10.0.2.15  Bcast:10.0.2.255  Mask:255.255.255.0
          inet6 addr: fe80::a00:27ff:fe7c:a207/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1

eth0      Link encap:Ethernet  HWaddr 08:00:27:7c:a2:07  
          inet6 addr: fe80::a00:27ff:fe7c:a207/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1

Should now have network connectivity from this machine, via br-int.

(how do I know gateway should be 10.0.2.2, is this something I can set in VirtualBox?)
(Answer: VirtualBox assigns IPs based on its built-in DHCP server.  Its first network
 is 10.0.2.0, then 10.0.3.0, etc.)

    $ sudo nano /etc/ovs-ifup
#!/bin/sh
switch='br-int'
/sbin/ifconfig $1 0.0.0.0 up promisc
ovs-vsctl add-port ${switch} $1

    $ sudo nano /etc/ovs-ifdown
#!/bin/sh
switch='br-int'
/sbin/ifconfig $1 0.0.0.0 down
ovs-vsctl del-port ${switch} $1

    $ chmod +x /etc/ovs-ifup /etc/ovs-ifdown
    
Nested VM, using image linux-0.2.img    
    $ sudo kvm -m 256 -net nic,macaddr=00:00:00:00:cc:10 \
           -net tap,script=/etc/ovs-ifup,downscript=/etc/ovs-ifdown \
           -hda linux-0.2.img &
           
    $ sudo kvm -m 256 -net nic,macaddr=00:00:00:00:cc:20 \
           -net tap,script=/etc/ovs-ifup,downscript=/etc/ovs-ifdown \
           -hda linux-0.2.img &           
           
WAHOOO finally got it!

Adding a GRE tunnel
    $ ovs-vsctl add-port br1 gre0 -- set interface gre0 type=gre options:remote_ip=10.0.2.15

TODO: Try this - http://networkstatic.net/wp-content/uploads/2012/04/openvswitch.openflow.gre_.tutorial1.pdf

Dec 17:

Change terminal prompt by:
    $ nano ~/.bashrc
Add at end of file:
PS1='$PWD #  '

Install Floodlight OVS Controller:
    $ git clone git://github.com/floodlight/floodlight.git
    $ sudo apt-get install build-essential default-jdk ant python-dev eclipse
    $ cd floodlight
    $ sudo ant
    $ sudo java -jar target/floodlight.jar
Add OVS bridges
    $ ovs-vsctl set-controller br1 tcp:10.0.2.15:6633
    
Do this for both ends of the gre tunnel

Floodlight VM might be easier...
http://floodlight-download.projectfloodlight.org/files/floodlight-vm.zip

Other controllers:
nox, pox, ryu, opendaylight
Reading: http://www.nec-labs.com/~lume/sdn-reading-list.html

Jan 6:

In openvswitch, there is a folder: tutorial.  Learn more about openvswitch from this doc.
On Ubuntu OVS1, followed floodlight install
- might have worked, but didn't bind tot he correct port
- trying instead with a floodlight VM
  - in files from floodlight-vm.zip, copy to a directory and from this
    directory run ./floodlightcontroller.vbox.sh
  - modify /etc/resolve.conf with appropriate nameserver (8.8.8.8 works)
  - assign ip addresses to interfaces
  - get floodlight:
    - running into issues with apt-get install...
Made a new VM: Ubuntu OVS Controller
Will install floodlight on this one per method above
- Installation complete, floodlight works

On OVS1, followed link:  http://networkstatic.net/open-vswitch-on-virtualb
Add the following repo to /etc/apt/sources.list 
    $ deb http://download.virtualbox.org/virtualbox/debian precise contrib

--- Left off here, can't figure out why network interfaces are always reconfiguring themselves



    $ wget -q http://download.virtualbox.org/virtualbox/debian/oracle_vbox.asc -O- | sudo apt-key add -
    $ sudo apt-get update
    $ sudo apt-get install dkms
    $ sudo apt-get install virtualbox-4.2

Jan 7:

From Dec 13,
    TODO:
    For slices that don't belong to tenant requesting wnet-add-wslice, deny
    Implement message passing to state denied request for non-existant slice
    For gateway, command should be something like wnet-join-subnet
    When deleting a wnet, change associated ap_slices to wnet = Null
    wnet-show should list details of wnet as well as associated slices
    In wnet-rem-tag exception for nonexistant tag
    Change names to wnet-add-tag, wnet-remove-tag
    
- manager.ap_slice_show() does not work properly, it makes an incorrect call to
  ap-slice-list
- ap-slice-list doesn't mesh with the way ap-slice-show passes filter arg

--> fixed ap-slice-list, ap-slice-show to have expected result
--> TODO: use this to make wnet-show display details
--> Removed index [0] from items in ap-slice-create

Setting up github:
    $ git config --global user.name "Mike.Kobierski"
    $ git config --global user.email "michael.kobierski@mail.mcgill.ca"
Make a directory matching the online project repository.  In that directory:
    $ git init
    $ git remote add origin https://github.com/savi-bcrl/aurora.git
    $ git remote -v #to check
    $ git remote set-branches origin dev
    $ git pull
    
##### different method    
    
    $ git clone https://github.com/savi-bcrl/aurora.git
    $ cd aurora
    $ git branch -a
    $ git checkout origin/dev  #This changes the files in pwd to match!
    
I began developing from commit d3d13c4a610832547be46fd4ac7f55e96fa4359f
    $ git checkout -b dev-MK d3d13c4a610832547be46fd4ac7f55e96fa4359f
    $ git push origin dev-MK
    
Now copy relevant files, can see they copied.
    $ git status
    
Commit new branch to project
    $ git add *
    $ git commit -m "Make many changes mainly to make some wnet functionality in manager.py and make it testable"
    $ git push origin dev-MK

Useful git crash course
    http://wireless.kernel.org/en/developers/Documentation/git-guide

Jan 8:

Merging code with current on github.
Adding command line support for typing aurora.
Usage: aurora [-n] [args]

--> Created aurorainstall.py, enabling command line control of aurora

Team member: Feier

--> Merged wnet functions in manager() into recent code on GitHub
To update dev-MK to dev while working in dev but without modifying dev's remote
In dev:
    $ git commit
    $ git checkout dev-MK
    $ git merge dev
    $ git status
Fix unmerged paths by manually editing files
  ( alternatively,
    $ git mergetool
  )
    $ git add *
    $ git status
    $ git commit -m "Message"
    $ git checkout dev
  
    $ git push origin dev-MK
    
Viewing visual history of a repository:
    $ git log --all --graph --pretty=tformat:'%Cred%h%Creset -%C(yellow)%d%Creset%s\
      %Cgreen(%an %cr)%Creset' --abbrev-commit --date=relative

Git stopped working?  I think they are having issues...  Receiving 403 Error.

To update a specific file from one branch to another,
Ex, from dev to dev-MK, file SendJSON.py:
    $ git checkout dev-MK
    $ git diff dev-MK..dev auroraclient/SendJSON.py | git apply --index && git commit

Useful git info:
    http://sethrobertson.github.io/GitFixUm/fixup.html

Next: Continue the todo list from Jan 7 with merged code.

Jan 9:

Something to read about message passing:
    http://pika.readthedocs.org/en/0.9.13/intro.html
    
Useful commands for additional terminals in ssh:
    $ screen
- ctrl+d terminates screen
- ctrl+a then ctrl+d detaches screen
- ctrl+a c makes new window
- ctrl+a w or ctrl+a " show windows
- ctrl+a M to monitor 
- ctrl+a ? for help
- ctrl+a [ for window history
    $ screen -r
- ctrl+a : caption always '%w'
         : resize +N (N is num lines)
Quick reference: http://aperiodic.net/screen/quick_reference
   
auroramanger is run on an ssh session, the '-n' option doesn't work

rabbitMQ configuration file installation

/usr/lib/rabbitmq/lib/rabbitmq_server-2.7.1/sbin/rabbitmq-plugins list

http://www.rabbitmq.com/install-debian.html

    $ sudo rabbitmq-plugins enable rabbitmq_management
    $ sudo service rabbitmq-server restart
    $ sudo rabbitmqctl list_users
    $ sudo rabbitmqctl change_password guest secret

Web interface is at http://localhost:15672
username: guest
password: guest

Username: heming
Password: secret
Username: outside_world
Password: wireless_access
Need to change permissions of outside_world to / .* .* .*

When getting a socket address in use error:
    $ killall python
    
Jan 10:

Fixing incorrect merge into dev from dev-MK
    $ sudo apt-get install gitk
    $ gitk --date-order
    
ap_slice_restart incorrectly calls ap_slice_delete, ap_slice_create
--> Streamlined ap_slice_add_tag

Jan 13:

To tell git to ignore a specific file (in my case auroraclient/shell.py)
    $ git update-index --assume-unchanged auroraclient/shell.py
To undo
    $ git update-index --no-assume-unchanged auroraclient/shell.py

To delete a branch (local and remote)
    $ git branch -d dev-MK
    $ git push origin :dev-MK
    $ git branch -d origin/dev-MK

In database, name shouldn't be globally unique, only unique to individual tenants.

Left off revising ap_slice_filter for location tags

Jan 14:

Using ap-slice-create with a tag seems to create a slice with a tag seems to assign
tag to "slice" in config json, which is actually the name of the slice.  Is this right?

Should implement multiple users for MySQL (resourceMonitor, auroraDB, manager)
so queries don't conflict

For wnet-create, syntax is aurora wnet-create wnet-1.  Why does documentation look like:
usage: aurora wnet-create [-h] [--slice [slices/tags [slices/tags ...]]]
                          [--file FILE]
                          name

positional arguments:
  name

optional arguments:
  -h, --help            show this help message and exit
  --slice [slices/tags [slices/tags ...]], --tag [slices/tags [slices/tags ...]]
                        List of slices or tags
  --file FILE           JSON config file

Jan 15:

Add status indicator to ap-slice-list.
aurora ap-slice-list shows everything except deleted, use '-a' for all.
--> Added -a option for ap-slice-list
--> Fixed RabbitMQ race condition bug

Jan 16:

Installing devstack
    $ git clone https://github.com/savi-dev/devstack
    $ cd devstack
    $ git checkout silver-
    $ sudo ./install_client.sh
    $ source openrc heming mcgill EDGE-MG-1 iam.savitestbed.ca
    $ export OS_PASSWORD=jhBvtv5D
    $ nova list


    $ ssh ubuntu@132.206.206.133
password: savimcgill

    $ tail /var/log/syslog
    $ ssh root@10.5.8.207
password: openflow
(
    $ ps ea | grep caps
    $ /etc/init.d/capsulator disable
)
To see if aurora is running
    $ ps ea | grep aurora
2 ways:
Daemon commands
    $ /etc/init.d/aurora
Or screen
    $ screen
    $ cd /usr/aurora/
    $ python /usr/aurora/Receive.py
    (use full path so /etc/init.d/aurora stop works properly)

10.5.8.236 - openflow1 (00:0d:b9:2b:b7:c4)
10.5.8.208 - openflow2 (00:0d:b9:2b:b6:e8)
10.5.8.207 - openflow3 (00:0d:b9:25:34:3c)
10.5.8.2 - DHCP Server? (fa:16:3e:c0:18:a2)
10.5.8.3 - auroramanager (fa:16:3e:ae:25:73)
10.5.8.1 - gateway (fa:16:3e:de:db:5c)
lab laptop (00:21:5d:22:97:8c)


Git stashing:
    $ git stash
    $ git stash list
    $ git stash apply
    $ git stash apply@{2}
    $ git stash drop
    
Ran into issue of messages apparently not being delivered correctly to ap.
- check that only one instance of Receive.py is running...
 
TODO: Set up a ping to bring pika message passing online

Jan 17:

When creating a slice, need to have provision_server update ap table
to modify number of radios in use.

- BSS details are in /etc/config/wireless
    $ cat /etc/config/wireless

Each access point should be configured individually so SSIDs,channels dont overlap

Unplugging access point mark ap_slice status down
Plugging back in, should send reset command

Jan 20:

Should store access point state so slices are persistent when access point is reset
Num radios / available slices should be updated in MySQL when slices are created / deleted
For slices to join a subnet, they should be tunneled (or routed with openflow) to the desired
 network where a usi

What does this do?
    $ netstat

Should store slice ssid in MySQL database for easy reference
Managed to make an OVS slice, it is slowwwwwwww.

Also tried to make some custom rules, though am having trouble testing them.
Followed instructions for OpenDaylight Controller on auroramanager (132.206.206.133):
    http://networkstatic.net/installing-mininet-opendaylight-open-vswitch/
    $ apt-get install maven git openjdk-7-jre openjdk-7-jdk unzip
    $ wget https://jenkins.opendaylight.org/controller/job/controller-merge/lastSuccessfulBuild/artifact/opendaylight/distribution/opendaylight/target/distribution.opendaylight-osgipackage.zip
    $ unzip distribution.opendaylight-osgipackage.zip
    $ cd opendaylight
    $ export JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-amd64
    $ ./run.sh
    
To set JAVA_HOME over reboots:
    $ nano ~/.bash_profile
Add to file:
    export JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-amd64
    export PATH=$PATH:$JAVA_HOME
To load:
    $ source ~/.bash_profile
    OR
    $ . ~/.bash_profile
Verify:
    $ echo $JAVA_HOME
    $ echo $PATH
(Could use ~/.bashrc instead)

Can access at http://10.5.8.3:8080
    username: admin
    password: admin
    
For OVS slices, some issues with DHCP cause connection timeout.  Set static.
aurora ap

Jan 21:

Team member: HP

Laptop credentials
    username: savi
    password: mc838tln
    
Manually connecting to a network by command line:
    http://www.backtrack-linux.org/forums/showthread.php?t=19448
    https://help.ubuntu.com/community/WifiDocs/WiFiHowTo
    $ su
Wireless interface down by lock: use rfkill utility
    $ sudo rfkill list
    $ sudo rfkill unblock 0

    # ifconfig wlan0 up
    # iwlist wlan0 scan
    # iwconfig wlan0 essid off ap off key off
    # iwconfig wlan0 mode managed
    # iwconfig wlan0 channel 2
    # iwconfig wlan0 essid [network name] key s:[key]
    # dhclient wlan0

on lab laptop, install nm-applet in network-tools-gnome

Jan 22:

Some issue with mysql when server has been left a long time 
error "MySQL has gone away".

test bandwidth with iperf
    $ iperf -s
    $ iperf -c 10.5.8.3

Should make another MySQL table to track slice SSID

For Openflow QOS: http://users.ecs.soton.ac.uk/drn/ofertie/openflow_qos_mininet.pdf

To capture for wireshark:
    $ tcpdump -i <interface> -s 65535 -w <some-file>
    
from 10.5.8.227 ping 10.5.8.3
from 10.5.8.201 ping 10.5.8.227
from 10.5.8.201 ping 10.5.8.208

For wireshark with OF: 
    http://networkstatic.net/installing-wireshark-on-linux-for-openflow-packet-captures/
    $ sudo apt-get install wireshark-dev
    $ sudo apt-get install mercurial
    $ hg clone https://bitbucket.org/barnstorm/of-dissector
    $ cd of-dissector/src
    $ apt-get install scons
    $ export WIRESHARK=/usr/include/wireshark/
    $ scons install
This creates a shared object (so) named openflow.so.
Copy openflow.so to the Wireshark plugin directory.
    $ cp openflow.so /usr/lib/wireshark/libwireshark1/plugins/openflow.so

https://mailman.stanford.edu/pipermail/openflow-discuss/2012-April/003165.html
Wireshark and some dependencies:

    $ sudo apt-get install wireshark libgtk2.0-dev
    $ sudo apt-get install git-core automake m4 pkg-config libtool

 Dissector:

    $ git clone git://gitosis.stanford.edu/openflow.git
    $ cd openflow
Edit file “utilities/wireshark_dissectors/openflow/packet-openflow.c”,
add:
*#define NO_STRINGS NULL*
edit:
*void proto_reg_handoff_openflow*()
{
    openflow_handle = create_dissector_handle(dissect_openflow, proto_openflow);
    //dissector_*add*(TCP_PORT_FILTER, global_openflow_proto, openflow_handle);
    dissector*_add_uint*(TCP_PORT_FILTER, global_openflow_proto, openflow_handle);
}

    $ ./boot.sh
    $ ./configure
    $ sudo make
    $ sudo make install
    $ cd utilities/wireshark_dissectors/openflow
    $ make
    $ sudo make install

Not appearing in Wireshark → About → Plugin
copy the packet-openflow.so file in the location of the libraries
    $ cp [file] [destination_path]
for me it is /usr/lib/wireshark/libwireshark1/plugins

Wireshark will not recognize the plugin:


On openflow3, launch blank radio profile, then manually set up ovs:
    $ mkdir /tmp/of; cd /tmp/of
    $ ovsdb-tool create /tmp/of/conf /usr/share/openvswitch/vswitch.ovsschema
    $ ovs-server --remote=punix:/tmp/of/db.sock /tmp/of/conf --detach
    $ ovs-vswitchd unix:/tmp/of/db.sock --detach
    $ ovs-vsctl --db=unix:/tmp/of/db.sock add-br ovbr
    $ ifconfig ovbr up
    $ ovs-vsctl --db=unix:/tmp/of/db.sock add-port ovbr veth0
    $ ovs-vsctl --db=unix:/tmp/of/db.sock add-port ovbr vwlan0
    $ 

to use find:
    $ find / -name tcpdump 
     
Capture multiple for time period:
    $ /usr/sbin/tcpdump -i wlan0 -s 65535 -w of2-wlan0-ovs-3 & \
        /usr/sbin/tcpdump -i veth0 -s 65535 -w of2-veth0-ovs-3 & \
        /usr/sbin/tcpdump -i eth0 -s 65535 -w of2-eth0-ovs-3 & \
        sleep 60s && pkill -HUP -f /usr/sbin/tcpdump 
        
    $ tcpdump -i eth0 -s 65535 -w m-eth0-ovs-3
        
Jan 23:

Reading: http://virtualnow.net/2012/05/03/using-an-openflow-switch-as-a-programmable-patch-panel/
Each OpenFlow switch needs a unique DPID (datapath ID)        

To restart AP:
    $ reboot
    $ uptime
On manager to view leases:
    $ cat /var/sys/syslog

    
from of2 ping 10.5.8.1
start receive
make slice
from manager ping 10.5.8.208
join laptop
from laptop ping 10.5.8.3
shutdown slice 
        
        
of(1) vwlan0
of(2) veth0
        
packet of interest: m 1334

Jan 27:

QoS: Use "FlowScale"
        
Floodlight basics:
UI:
    http://localhost:8080/ui/index.html

To push a flow:
    $ curl -d '{"switch": "00:00:6a:15:71:68:31:4b", "name":"static-flow1", \
      "priority":"32768", "dst-mac":"00:00:00:00:cc:10","active":"true", \
      "actions":"output=2"}' http://localhost:8080/wm/staticflowentrypusher/json

To query switches:
    $ curl http://localhost:8080/wm/core/controller/switches/json

To query all flows
    $ curl http://localhost:8080/wm/core/switch/00:00:5c:26:0a:5a:c8:b2/flow/json
      
To query flows:
    $ curl http://localhost:8080/wm/staticflowentrypusher/list/00:00:6a:15:71:68:31:4b/json
    
To clear flows:
    $ curl http://localhost:8080/wm/staticflowentrypusher/clear/00:00:5c:26:0a:5a:c8:b2/json   

Open vSwitch slices seem to work.
When making a new slice on the same AP, latency increases momentarily

    $ curl -d '{"switch": "00:00:fe:c0:6e:41:eb:48", "name":"static-1", \
        "dst-mac":"00:21:5d:22:97:8c", "active":"true", "actions":"output=1"}' \
        http://10.5.8.3:8080/wm/staticflowentrypusher/json
        

        
Print nicely: pipe to python -mjson.tool:
    $ curl http://10.5.8.3:8080/wm/core/switch/00:00:fe:c0:6e:41:eb:48/flow/json | python -mjson.tool

Jan 28:

--> Worked on creating resiliency across AP interruptions.
--> TODO: Pass user database back to manager
--> TODO: Set up slices from initial stored config      

vi basics:
Two modes, command (press ESC to get here), and insert (press 'i').
In command mode, write with :w, quit with :q
Tab options :set expandtab :set tabstop=4 :retab
Config file:
    $ vi ~/.vimrc

Jan 29:

--> Completed slice resiliency code - slices will be reinstantiated upon AP restart

Jan 30:
    
Researching QoS.  Use linux tc (See michael's document), or future OpenFlow functionality.
Rate limiting was added in OF version 1.2.
http://docs.projectfloodlight.org/display/floodlightcontroller/How+to+implement+Quality+Of+Service+using+Floodlight

ssh without password:

    $ cd ~/.ssh
    $ ssh-keygen -t rsa
    Choose no passphrase when asked and accept the default filename of id_rsa
    $ scp id_rsa.pub <user>@<yourhost>:.ssh/authorized_keys
    Provide your password when asked and that’s the last time you’ll have to do it!
    
TODO: Somehow create a default radio profile so first slice can be created without
      specifying a config.
      Also, check if radio already configured when additional slices are created.
      If yes, use existing radio config.

Jan 31:

Sublime text, download from website.  
Move to something like /usr/local/bin/Sublime Text 2.
Create a link in /usr/local/bin.
    $ cd /usr/share/applications
    $ sudo cp sol.desktop sublime.desktop
    $ gksudo gedit sublime.desktops
Modify file to be
--------------------
[Desktop Entry]
Name=Sublime Text 2
Comment=Nice clean text editor
Exec=sublime %f
Icon=/usr/local/lib/Sublime Text 2/Icon/48x48/sublime_text.png
MimeType=text/plain;
Terminal=false
Type=Application
Categories=Utility;TextEditor;
X-GNOME-FullName=Sublime Text 2
StartupNotify=true
X-HildonDesk-ShowInToolbar=true
X-Osso-Type=application/x-executable

edit ~/.local/share/applications/mimeapps.list
--------------------
[Added Associations]
application/x-executable=gedit.desktop;
text/plain=sublime.desktop;
text/x-python=sublime.desktop;

[Default Applications]
text/plain=sublime.desktop
text/x-python=sublime.desktop

Quick reference:
    http://dereckrx.com/posts/sublime-text-2-quick-reference/

Change name to aurora-ap on AP:
Add to Receive.py:
#!/usr/bin/python -tt

    $ chmod +x /usr/aurora/Receive.py
    $ ln -s /usr/aurora/Receive.py /usr/bin/aurora-ap
    $ aurora-ap
    
Show directory size:
    $ du -h
    
On auroramanager, install floodlight-qos app:
    $ git clone https://github.com/wallnerryan/floodlight-qos-beta.git

Create ovs slice, connect laptop.
Benchmark bandwidth: 16.9Mbits / 17.0Mbits / 16.2Mbits

http://www.youtube.com/watch?v=M03p8_hJxdc
from ~/floodlight-qos-beta/apps/qos:
    $ ./qosmanager2.py -c localhost -p 8080 -s #status
    $ ./qosmanager2.py -c localhost -p 8080 -e #enable
    $ ./qosmanager2.py -c localhost -p 8080 -L -t services
    $ ./qosmanager2.py -c localhost -p 8080 -L -t policies

On AP (switch), create 3 queues, one with default qos, one with 20Mbits/s, one with 2Mbits/s
    $ sudo ovs-vsctl -- set port vwlan0 qos=@defaultqos -- \
        --id=@defaultqos create qos type=linux-htb other-config:max-rate=1000000000 queues=0=@q0,1=@q1,2=@q2 -- \
        --id=@q0 create queue other-config:min-rate=1000000000 other-config:max-rate=1000000000 -- \
        --id=@q1 create queue other-config:max-rate=20000000 -- \
        --id=@q2 create queue other-config:max-rate=2000000 other-config:min-rate=2000000
    $ ./qospath2.py -p 8080 -c localhost -a -N limit_slice -S 10.5.8.217 -D 10.5.8.3 -J '{"eth-type":"0x0800","protocol":"6","queue":"2"}'

can see policies at:
    $ curl http://10.5.8.3:8080/wm/staticflowentrypusher/list/all/json | python -mjson.tool
    $ curl http://10.5.8.3:8080/wm/qos/policy/json | python -mjson.tool

Delete by
    $ ./qospath2.py -d -N limit_slice
    
Working QOS configuration:
    $ curl http://localhost:8080/wm/staticflowentrypusher/list/00:00:ee:27:b3:70:07:43/json | python -mjson.tool
{
    "00:00:ee:27:b3:70:07:43": {
        "limit_slice.00:00:ee:27:b3:70:07:43-1353726753": {
            "actions": [
                {
                    "length": 16, 
                    "lengthU": 16, 
                    "port": 2, 
                    "queueId": 2, 
                    "type": "OPAQUE_ENQUEUE"
                }
            ], 
            "bufferId": -1, 
            "command": 0, 
            "cookie": -1608806909, 
            "flags": 0, 
            "hardTimeout": 0, 
            "idleTimeout": 0, 
            "length": 88, 
            "lengthU": 88, 
            "match": {
                "dataLayerDestination": "00:00:00:00:00:00", 
                "dataLayerSource": "00:00:00:00:00:00", 
                "dataLayerType": "0x0800", 
                "dataLayerVirtualLan": -1, 
                "dataLayerVirtualLanPriorityCodePoint": 0, 
                "inputPort": 0, 
                "networkDestination": "10.5.8.3", 
                "networkDestinationMaskLen": 32, 
                "networkProtocol": 6, 
                "networkSource": "10.5.8.217", 
                "networkSourceMaskLen": 32, 
                "networkTypeOfService": 0, 
                "transportDestination": 0, 
                "transportSource": 0, 
                "wildcards": 3145935
            }, 
            "outPort": -1, 
            "priority": 32767, 
            "type": "FLOW_MOD", 
            "version": 1, 
            "xid": 0
        }
    }
}

    $ curl -d '{"switch": "00:00:ee:27:b3:70:07:43","name":"qos1","priority":"32767", \
               "src-ip":"10.5.8.217","ether-type":"0x0800","active":"true","actions":"enqueue=2:2"}' \
               http://localhost:8080/wm/staticflowentrypusher/json
    $ curl -d '{"switch": "00:00:ee:27:b3:70:07:43","name":"qos2","priority":"32767", \
               "dst-ip":"10.5.8.217","ether-type":"0x0800","active":"true","actions":"enqueue=1:2"}' \
               http://localhost:8080/wm/staticflowentrypusher/json
               
To delete a flow
    $ curl -X DELETE -d '{"name":"qos1"}' http://10.5.8.3:8080/wm/staticflowentrypusher/json
    
View flows:
    $ curl http://10.5.8.3:8080/wm/core/switch/all/flow/json | python -mjson.tool

On AP
    $ ovs-vsctl --db=unix:/tmp/tmpRBaa1n -- set port vwlan0-1 qos=@defaultqos -- \
        --id=@defaultqos create qos type=linux-htb other-config:max-rate=1000000000 queues=0=@q0,1=@q1,2=@q2 -- \
        --id=@q0 create queue other-config:min-rate=1000000000 other-config:max-rate=1000000000 -- \
        --id=@q1 create queue other-config:max-rate=20000000 -- \
        --id=@q2 create queue other-config:max-rate=2000000 other-config:min-rate=2000000

    $ ovs-vsctl --db=unix:/tmp/tmpRBaa1n -- set port veth1 qos=@defaultqos -- \
        --id=@defaultqos create qos type=linux-htb other-config:max-rate=1000000000 queues=0=@q0,1=@q1,2=@q2 -- \
        --id=@q0 create queue other-config:min-rate=1000000000 other-config:max-rate=1000000000 -- \
        --id=@q1 create queue other-config:max-rate=20000000 -- \
        --id=@q2 create queue other-config:max-rate=2000000 other-config:min-rate=2000000

From tenant machine?
    $ curl -d '{"switch": "00:00:0a:36:e3:72:59:48","name":"qos1","priority":"32767", 
               "src-ip":"10.5.8.217","ether-type":"0x0800","active":"true","actions":"enqueue=2:2"}' \
               http://10.5.8.3:8080/wm/staticflowentrypusher/json
    $ curl -d '{"switch": "00:00:0a:36:e3:72:59:48","name":"qos2","priority":"32767", 
               "dst-ip":"10.5.8.217","ether-type":"0x0800","active":"true","actions":"enqueue=1:2"}' \
               http://10.5.8.3:8080/wm/staticflowentrypusher/json

Feb 3:

Editing Prabhat's paper: OpenMan: A Management Framework for virtualized Wireless Networks


http://lartc.org/howto/lartc.qdisc.html

    $ tc qdisc del dev eth0 root
    $ tc qdisc add dev eth0 root handle 1: htb
    $ tc class add dev eth0 parent 1: classid 1:1 htb rate 2mbit
    $ tc filter add dev eth0 parent 1:0 protocol ip \
        prio 1 u32 match ip dst 0.0.0.0/0 flowid 1:1
    
    $ tc qdisc add dev eth0 root tbf rate 250000bps latency 50ms burst 100000
    
    $ tc qdisc add dev eth0 root tbf rate 1.9mbit latency 50ms burst 100000 
    $ iperf -c 10.5.8.3 -f k  
------------------------------------------------------------       
Client connecting to 10.5.8.3, TCP port 5001
TCP window size: 21.0 KByte (default)        
------------------------------------------------------------   
[  3] local 10.5.8.236 port 58581 connected with 10.5.8.3 port 5001
[ ID] Interval       Transfer     Bandwidth
[  3]  0.0-10.9 sec  2688 KBytes  2018 Kbits/sec
    
Show qdisc on interface
    $ tc -s qdisc ls dev eth0

QoS on OpenWRT
https://forum.openwrt.org/viewtopic.php?id=2429
http://wiki.openwrt.org/doc/howto/packet.scheduler/packet.scheduler  
http://www.rooot.net/en/geek-stuff/openwrt/1-qos-openwrt.html
http://serverfault.com/questions/350023/tc-ingress-policing-and-ifb-mirroring

Limit down traffic, use ifb
    $ modprobe ifb numifbs=1
    $ ip link set dev ifb1 up
    $ tc qdisc add dev eth0 handle ffff: ingress
    $ tc filter add dev eth0 parent ffff: protocol ip u32 match u32 0 0 action mirred egress redirect dev ifb1
    $ tc qdisc add dev ifb1 root handle 1: htb default 10
    $ tc class add dev ifb1 parent 1: classid 1:1 htb rate 1mbit
    $ tc class add dev ifb1 parent 1:1 classid 1:10 htb rate 1mbit

Feb 4:

--> Assign access points static IPs for easier ssh access
http://wiki.openwrt.org/doc/uci/network?s[]=interfaces#protocol.static

To use serial connection to AP
    $ sudo apt-get install minicom
    $ dmesg | grep tty
    $ minicom -s
    Set Bps : 38400 8N1
    Set serial device /dev/ttyUSB0
    $ minicom
    
Wireshark over ssh
    $ ssh ubuntu@132.206.206.133 'sudo tcpdump -i eth0 -s 65535 
        -U -w - "not port 22"' | wireshark -k -i -
    $ ssh savi@132.206.206.131 'sudo tcpdump -i qr-f79e9386-f9 
        -s 65535 -U -w - "not port 22"' | wireshark -k -i -

If using openflow and want to filter ssh traffic:
    of.match_nw_proto != 22


WHY DOESN'T MANAGER PING AP's ANYMORE?

Feb 5:

Must have been some dhcp issues...

openflow1 - 236
openflow2 - 208
openflow3 - 207

--> Added ssid to mysql table and ap-slice-list
  > ALTER TABLE ap_slice ADD ap_slice_ssid VARCHAR(255) AFTER ap_slice_id;

Feb 6:

Use iftop to monitor bandwidth.
Could use bmon instead...

Monitor with vnstat
http://wiki.openwrt.org/doc/howto/vnstat
    $ opkg update
    $ opkg install vnstat
    $ /etc/init.d/vnstat enable
    $ /etc/init.d/vnstat start
/etc/config/vnstat is the database restore config, not the vnstatd config.
vnstatd config is located at /etc/vnstatd.conf

other option - watch ifstat and note peak:
    $ ifstat -b
    
For development, based on test results with no rate limiting, wifi link supports 
    
AnalogDevices
Intersil

--> Added QoS to slice using tc
TODO: Some bugs exist in adding entry to database, most likely db doesn't 
create the key for "TrafficAttributes".  Why?

Feb 7:

Phuoc - request_verification
Yang - CLI

To do: Two documents, one progress report, and one functionality for demo
Search for FMC for Robert

Add usb wireless device in Linux Mint:
    $ sudo apt-get install wireless-tools
    $ lsusb -v
    
http://wireless.kernel.org/en/users/Drivers/p54
Download USB 2nd generation (ISL3887) for 2.6.29 kernels and above:
    http://daemonizer.de/prism54/prism54-fw/fw-usb/2.13.25.0.lm87.arm
Copy downloaded file to /lib/firmware and name it isl3887usb
Unload and reload driver module
    $ modprobe -r p54usb
    $ modprobe p54usb
Reconnect the usb device.  Troubleshoot any issues from dmesg
    $ dmesg
    $ iwconfig
In Linux mint, disable network-manager or use it to connect.

Use htop as system monitor

Flashplugin install for firefox
    $ sudo apt-get install flashplugin-nonfree

OF setting up static flows connecting port 1 and 2

    $ curl -d '{"switch":"00:00:3a:8f:0a:25:c3:47","name":"s-1","active":"true",
        "ingress-port":"1","actions":"output=2"}' http://10.5.8.3:8080/wm/staticflowentrypusher/json
    $ curl -d '{"switch":"00:00:3a:8f:0a:25:c3:47","name":"s-2","active":"true",
        "ingress-port":"2","actions":"output=1"}' http://10.5.8.3:8080/wm/staticflowentrypusher/json
        
Next up, implement tc using OF queues?

Feb 10:

http://www.cafepy.com/article/python_types_and_objects/python_types_and_objects.html
https://www.ibm.com/developerworks/aix/library/au-cleancode/
pygenie: https://aufather.wordpress.com/2010/08/21/python-cyclomatic-complexity-pygenie/
        
--> Created ovs-tc module
Controller commands to enqueue:
    $ curl -d '{"switch": "00:00:32:8c:4f:25:45:43","name":"qos1",
              "ingress-port":"1","active":"true","actions":"enqueue=2:0"}' \
              http://localhost:8080/wm/staticflowentrypusher/json
        
Fix OVS traffic control

Feb 11:

ArgoUML

Open vSwitch concepts:
    http://docs.openstack.org/trunk/install-guide/install/zypper/content/concepts-neutron.openvswitch.html

Find (scan) machines within ip range on network
    $ nmap 10.5.8.0/24
    
Capsulator info
    http://archive.openflow.org/wk/index.php/Capsulator

TODO: Figure out why OVS QoS only works sometimes

Note, if unable to ping manager, it is due to dhcp issues.  Release and renew ip.

Changed ips of access points, they are now:
10.5.8.201 - openflow1
10.5.8.202 - openflow2
10.5.8.203 - openflow3

Feb 12:

Out of office

Feb 13:

--> update AP hardware info
--> Change SQL ap table:
 > ALTER TABLE ap ADD number_slice_free INT(11);
 > ALTER TABLE ap MODIFY version VARCHAR(255);
 > ALTER TABLE ap MODIFY supported_protocol VARCHAR(255) Default 'a/b/g'; 
 > ALTER TABLE ap MODIFY status ENUM('UP','DOWN','UNKNOWN');

IF EXISTS(SELECT * FROM ap WHERE name='openflow')
    UPDATE ap SET region='m', firmware='asdf', 
                                    version='r444', number_radio=1, 
                                    memory_mb=256, free_disk=0, 
                                    number_radio_free=1, number_slice_free=2
                       WHERE name='openflow'
ELSE
    REPLACE INTO ap SET name='openflow', region='m', firmware='asdf', 
                                    version='r444', number_radio=1, 
                                    memory_mb=256, free_disk=0, 
                                    number_radio_free=1, number_slice_free=2, 
                                    status='UP'

INSERT INTO ap SET name='openflow', region='m', firmware='asdf', 
                                    version='r444', number_radio=1, 
                                    memory_mb=256, free_disk=0, 
                                    number_radio_free=1, number_slice_free=2, 
                                    status='UP'
    ON DUPLICATE KEY UPDATE 

Doesn't work as expected.
TODO: Add support for tracking ap status ('up','down', 'unknown')  

Feb 14:

Should add default radio config to provision files so AP can configure a slice
even if no radio info is provided.

--> Added support for updating ap status and hardware info in SQL database

Wireshark without root:
    http://packetlife.net/blog/2010/mar/19/sniffing-wireshark-non-root-user/
    $ setcap cap_net_raw,cap_net_admin=eip /usr/bin/dumpcap

Feb 17:

See who is logged in with:
    $ who
    
--> Add generation for uuid in dispatcher, removing need for correlation
    id 'FFF..FF'
--> Clean up deletion of timer threads in dispatcher and resource monitor

Memory info is found using:
    $ free
or
    $ cat /proc/meminfo
    
--> Add hw memory information tracking to MySQL database

TODO: Make AP wait for manager to come online for some timeout.

Feb 18:

For Dzung, capture some images of resource utilization on the AP for
different scenarios.
- some spike in utilization when creating and deleting slices
- some visible usage (40%) when pinging at 0.01 from a client
- 100% usage when using iperf from a client

--> Fix manager and AP communication, SYN, SYN/ACK, FIN work now
--> Commit relatively stable version to master

Feb 19:

Docstrings with formatting as reStructuredText
    http://sphinx-doc.org/domains.html#info-field-lists
    http://docutils.sourceforge.net/rst.html

Find circular references with objgraph, which relies on gc:
    http://engineering.hearsaysocial.com/2013/06/16/circular-references-in-python/
    $ sudo apt-get install graphviz
    $ pip install xdot objgraph

Logging:
    http://code.activestate.com/recipes/412552-using-the-loggingpytoh-module/
    http://css.dzone.com/articles/best-practices-python-logging
    https://pingbacks.wordpress.com/2010/12/21/python-logging-tutorial/
--> Fixed memory-leaking circular reference between dispatcher and
    resource_monitor
--> Began adding logging for cleaner debugging output

Feb 20:

--> Moved AccountingManager into ResourceMonitor module
--> Renamed ResourceMonitor to APMonitor
--> Renamed AccountingManager to UptimeTracker
--> Fixed StoppableThread
--> Created cls_logger module to handle creating class-level loggers
--> Replace all print statements with logger output

Feb 21:

--> Moved handle_response to ap_monitor module
--> Pass timeout and handle_response as callbacks to dispatcher
--> Implement more logging

TODO: Not sure why %s prints instead of argument

Feb 24:

--> Remove ap_slice_status table, append it to ap_slice table

Something doesn't quite work in setting the status for slices 
when AP dies and reconnects

Feb 25:

 > SELECT NOW(), last_active_time, sec_to_time(unix_timestamp(NOW()) 
            - unix_timestamp(last_active_time)) AS time_diff 
    from ap_slice 
        where ap_slice_id='04f36e84-88f1-4d2e-b9e0-961073b64af7';

--> Moved most of SQL access to aurora_db module
--> Fixed some issues with slices not restarting upon ap reconnect

Feb 26:

--> Remove dependence on ap_slice_status table in db
 > DROP TABLE ap_slice_status;
 > ALTER TABLE ap_slice CHANGE bytes_sent mb_sent FLOAT;

Playing with routing to determine how capsulator will work.
    $ sudo apt-get install iptables-persistent
rules are stored in /etc/iptables/rules.v4
https://help.ubuntu.com/community/Router
https://help.ubuntu.com/community/IptablesHowTo
To flush (reset) a config
    # iptables -F
    # iptables -X
    # iptables -t nat -F
    # iptables -t nat -X
    # iptables -t mangle -F
    # iptables -t mangle -X
    # iptables -P INPUT ACCEPT
    # iptables -P FORWARD ACCEPT
    # iptables -P OUTPUT ACCEPT

    # modprobe nf_conntrack
    # modprobe nf_conntrack_ftp
    # modprobe nf_conntrack_irc
    # modprobe ip_tables
    # modprobe iptable_nat
    # modprobe nf_nat_ftp
    
    # echo "1" > /proc/sys/net/ipv4/ip_forward
    # echo "1" > /proc/sys/net/ipv4/ip_dynaddr
    
List current rules
    # iptables -L -v -n
    
    $ sudo apt-get install kvm uml-utilities
    $ brctl addbr br-int
    $ brctl addif br-int eth1
    $ ifconfig eth1 0
    $ ifconfig br-int 10.0.10.10 netmask 255.255.255.0
    $ sudo nano /etc/br-ifup
#!/bin/sh
switch='br-int'
/sbin/ifconfig $1 0.0.0.0 up promisc
brctl addif ${switch} $1

    $ sudo nano /etc/br-ifdowns
#!/bin/sh
switch='br-int'
/sbin/ifconfig $1 0.0.0.0 down
brctl delif ${switch} $1

    $ sudo chmod +x /etc/br-ifup /etc/br-ifdown
    $ mkdir ~/QEMU; cd ~/QEMU
    $ wget http://wiki.qemu.org/download/linux-0.2.img.bz2
    $ bunzip2 linux-0.2.img.bz2 
    $ sudo kvm -m 256 -net nic,macaddr=00:00:00:00:cc:10 \
           -net tap,script=/etc/br-ifup,downscript=/etc/br-ifdown \
           -hda linux-0.2.img &
    $ sudo kvm -m 256 -net nic,macaddr=00:00:00:00:cc:20 \
           -net tap,script=/etc/br-ifup,downscript=/etc/br-ifdown \
           -hda linux-0.2.img &

Feb 27:

    $ cd ~
    $ git clone git://github.com/peymank/Capsulator.git
    $ sudo ln -s /usr/bin/make /usr/bin/gmake
    $ cd Capsulator
    $ make

https://blogs.oracle.com/fatbloke/entry/networking_in_virtualbox1#Internal
http://www.callum-macdonald.com/2009/10/28/virtualbox-host-to-guest-networking/?ModPagespeed=noscript

Promiscuous mode - pass all frames to kernel instead of only those intended for the VM in question

Feb 28:

Disable network manager:
    $ sudo stop network-manager
    $ echo "manual" | sudo tee /etc/init/network-manager.override

Set up following scenario:
            
                eth1                              eth2
          [ o ]----------------------------------------[ o ] 
    VB 1  [ v ] br-ext - 192.168.0.101/24 (eth1)       [ v ] br-ext - 192.168.0.102/24 (eth2) 
          [ v ] br-int - 10.1.1.1/24 (tap0)            [ v ] br-int - 10.1.1.2/24 (tap0)
          [ o ]                                  VB 2  [ o ]         
            | tap0 - 0.0.0.0                             | tap0 - 0.0.0.0
            |                                            |
            | eth0 - 10.1.1.20/24                        | eth0 10.1.1.30/24
    KVM 1 [ o ]                                        [ o ] KVM 2
    
on VB 1:
    $ brctl addbr br-ext
    $ brctl addif br-ext eth1
    $ brctl addbr br-int
    $ ifconfig br-ext 192.168.0.101/24
    $ ifconfig br-int 10.1.1.1/24
    $ ifconfig eth1 0
Launch KVM using command and scripts for br-ifup and br-ifdown from Feb 26

Similar commands on VB 2.

KVM 1 and KVM 2 should not be able to ping eachother, but VB 1 and VB 2 should.

In order for KVM 1 and KVM 2 to see eachother, use capsulator (Feb 27) on VB 1:
    $ sudo ./capsulator -t br-ext -f 192.168.0.102 -b br-int#0
and on VB 2:
    $ sudo ./capsulator -t br-ext -f 192.168.0.101 -b br-int#0
    
Now KVM 1 can ping KVM 2 and visa versa.

Now try with FlowVisor...
    https://github.com/OPENNETWORKINGLAB/flowvisor/wiki
    https://github.com/OPENNETWORKINGLAB/flowvisor/wiki/Installation-from-Binary

On VB 1:
    $ wget http://updates.onlab.us/GPG-KEY-ONLAB
    $ sudo apt-key add GPG-KEY-ONLAB
    $ echo "deb http://updates.onlab.us/debian stable/" >> /etc/apt/soruces.list
    $ sudo apt-get update
    $ sudo apt-get install flowvisor
    $ sudo -u flowvisor fvconfig generate /etc/flowvisor/config.json
password: secret
Make sure ovs-controller is not running:
    $ sudo pkill ovs-controller
Run flowvisor as user flowvisor
    $ sudo -u flowvisor flowvisor
    
Dumping config
    $ fvctl dumpConfig config.json
    
Useful information about using flowvisor (Outdated)
    http://groups.geni.net/geni/wiki/FlowVisor

FlowVisor Engineering Tutorial: Rob Sherwood
    https://www.youtube.com/watch?v=9cOgryOkN7M
    
Mar 3:

Set up a similar scenario, this time using openflow.
First set up and launch FlowVisor on VB 1 (Feb 28)
Run Floodlight controller on VB 1, set openflow port to 9933, by
set web-ui interface to port 8090:
    $ sudo cp ~/floodlight/src/main/resources/floodlightdefault.properties ~/floodlight/target/propfile
Add the lines:
    net.floodlightcontroller.core.internal.FloodlightProvider.openflowport=9933
    net.floodlightcontroller.restserver.RestApiServer.port=8090
Run Floodlight using new config file:
    $ sudo java -jar target/floodlight.jar -cf target/propfile


                eth1                              eth2
          [ o ]----------------------------------------[ o ] 
    VB 1  [ v ] br-ext - 192.168.0.151/24 (eth1)       [ v ] br-ext - 192.168.0.152/24 (eth2) 
          [ v ] br-int - 10.1.1.1/24 (tap0)            [ v ] br-int - 10.1.1.2/24 (tap0)
          [ o ]                                  VB 2  [ o ]         
            | tap0 - 0.0.0.0                             | tap0 - 0.0.0.0
            |                                            |
            | eth0 - 10.1.1.20/24                        | eth0 10.1.1.30/24
    KVM 1 [ o ]                                        [ o ] KVM 2
    
on VB 1:
    # ovs-vsctl add-br br-int
    # ovs-vsctl set-controller br-int tcp:192.168.0.101:6633
    # ifconfig br-int 10.1.1.1/24
    # ifconfig eth1 192.168.0.101
Launch KVM using command and scripts for br-ifup and br-ifdown from Feb 26

Similar commands on VB 2.

Now play with flowvisor on VB 1:
    $ man fvctl
    $ fvctl list-links
    $ fvctl add-slice first_slice tcp:192.168.0.101:9933 abysil@gmail.com
password: secret
    $ fvctl add-flowspace flowsp1 all 100 all first_slice=7
    
Running into issues with data and control plane separation 
https://groups.google.com/a/openflowhub.org/forum/#!topic/floodlight-dev/BErnyZykez0
https://groups.google.com/a/openflowhub.org/forum/#!forum/floodlight-dev

Wasn't successful with this quite yet, need to do more research.  Maybe prabhat
has a solution.

TODO:
    Rename rate-up and rate-down to uplink, downlink
    Continue exploring what flow based virtualization really means

Mar 4:

--> Updated metering to behave well

Mar 5:

--> Experiment with 8 slices and maximum bandwidth

For personal experiment on Mar 3:
Note: packets were circulating when bridges were created setting their controller to 192.168.0.102
when the ip address of eth2 was zeroed.  First create bridges, then zero ip of eth2 and move it to
br-ext
Use this script ovs-int_config.sh
------------------------
#!/bin/sh

ifconfig eth1 0 down
ovs-vsctl add-br br-ext
ovs-vsctl add-port br-ext eth2
ovs-vsctl set-controller br-ext tcp:192.168.0.101:6633
ovs-vsctl add-br br-int
ovs-vsctl set-controller br-int tcp:192.168.0.101:6633
ifconfig eth2 0
ifconfig br-ext 192.168.0.102/24
ifconfig br-int 10.1.1.2/24

Mar 6:

--> Make changes in ap_slice_create
--> Experimented with python documentation generation
    http://pythonhosted.org/an_example_pypi_project/sphinx.html#table-of-contents
    $ sudo apt-get install python-sphinx
    
Make a docs directory, then
    $ sphinx-quickstart
Configure index.rst, adding rst source and linking to other rst modules
Add module path to sys.path in conf.py
Run make
    $ make html

Mar 7:

To autogenerate python docs from docstrings, follow guide:
    https://codeandchaos.wordpress.com/2012/07/30/sphinx-autodoc-tutorial-for-dummies/
    $ sphinx-apidoc -F -o . <../core (source dir)>
add module directory to sys.path in doc/conf.py

Append to conf.extensions:
    'sphinx.ext.intersphinx'

Append to conf.py:

    intersphinx_mapping = {
        'python': ('https://docs.python.org/2.7/', None),
        'pika': ('http://pika.readthedocs.org/en/latest', None),
        'MySQLdb': ('http://mysqldb.readthedocs.org/en/latest/', None),
    }

    autodoc_default_flags = ['members', 'undoc-members', 'private-members', 
                             'show-inheritance']

    def autodoc_skip_member(app, what, name, obj, skip, options):
        if what == "exception" and name == "message":
            return True
        if what == "class" and name == "__init__":
            return False
        return skip

    def setup(app):
        app.connect('autodoc-skip-member', autodoc_skip_member)

Run:
    $ make html

To selectively document parts of code (Use case: exc.py has many member classes
which each have an associated message - include classes but don't include 
messages)
http://stackoverflow.com/questions/3757500/how-do-i-connect-sphinxs-autodoc-skip-member-to-my-function


Install apache on auroramanager
    http://www.maketecheasier.com/install-and-configure-apache-in-ubuntu/
    $ sudo apt-get install apache2 
    $ sudo cp /etc/apache2/sites-available/default /etc/apache2/sites-available/auroradocs
    $ nano /etc/apache2/sites-available/auroradocs
Change /var/www to html file directory
    $ sudo a2dissite default && sudo a2ensite auroradocs
    $ sudo service apache2 reload

Setting up password protection
    http://www.linuxhelp.net/guides/htaccess/
username: aurora-admin
username: aurora
password: savimcgill

Set site up on port 8001, open port 8001 using nova
    $ nova secgroup-add-rule aurora tcp 8001 8001 0.0.0.0/0

Command line web browsers:
    links, lynx, w3m
    
Made it easier to connect to openstack by adding the following to .bashrc
source /home/ubuntu/Lab838/devstack/openrc heming mcgill EDGE-MG-1 iam.savitestbed.ca
export OS_PASSWORD=jhBvtv5D 

http://www.tldp.org/LDP/Bash-Beginners-Guide/html/sect_03_02.html
To see environment variables:
    $ printenv
    
Mar 10:

Adding to python's path:n
    http://docs.python.org/2/install/index.html#modifying-python-s-search-path
    
Add python-auroraclient.pth to site-packages, containing only client dir.


To determine site-packages dir:
    $ python -m site
USER_SITE: '/home/ubuntu/.local/lib/python2.7/site-packages'

--> Added ap-slice-move functionality to manager and aurora_db
--> Tweaked auroraclient shell to allow 'required' options

Mar 11:

Flow isolation can be done with capsulator, tagging each port so traffic is only
duplicated on one interface.  Capsulate traffic between switch and tenant VM.

Can make multiple instances of capsulator.

--> Moved directory structure to be more openstack-like
--> Properly made aurora a package to import from

Mar 12:

Openstack Grizzly components
- Authentication (Keystone)
- Dashboard (Horizon)
- Object Storage (Swift)
- Image Service (Glance)
- Compute (Nova)
- Block Storage (Cinder)
- Networking (Quantum, Neutron in Havana)

Researched integration with Keystone

Mar 13:

Openstack uses bash scripts to install and configure certain elements.
--> Spent the afternoon learning the basics of bash programming

Mar 14:

--> Implemented a rudimentary ap_slice_restart

Mar 17:

--> Implemented prettytables output for ap_slice_list and ap_list

Mar 18:

--> Implemented passing tenant from client to manager
--> Bug fixes in AMQP message passing
--> Bug fix updating status of a 'DELETING' slice when access point connects
    - slice will now be marked 'DELETED', as it won't be restarted on that
      access point
TODO: Fix bug with ovs plugin - error opening json file.

Mar 19:

--> Fixed bug for ovs plugin, also fixed capsulator plugin (file read error)
--> Added aurorarc functionality to set tenant ID, project ID, and user ID

Currently implementing ap_slice_modify, starting with radio parameters
on auroraagent

TODO: restart_slice and modify_slice in aurora agent.

Mar 20:

--> Made progress on agent side of modify-slice
Issues: modifying the main slice is different than modifying an auxiliary slice
in that a main slice, when modifying something such as SSID, needs to 
uci commit and restart radios - all other bss will be deleted and will have
to be recreated.

TODO: Fix all Yang's changes - he finally added a commit to github but it may 
have broken many things.

Mar 21:

Origami for sublime text - support for multiple panes
https://github.com/SublimeText/Origami

Sublime package control
https://sublime.wbond.net/

Guide to sublime text 2
http://designmodo.com/sublime-text-2/

--> Continued working on modify slice for SSID parameters
--> Succeeded in creating a working backup and recreate function,
    where last know configurations can be stored in prev_database
    and reinstated should they break upon modification.
    
Still have to fix Yang's changes and remerge things in github.

Mar 24:

Fixed Yang's changes in manager and client so exceptions are caught and
bugs are minimized, though behaviour isn't as expected.
TODO: Change json-generation to be more user-friendly, create more logical
data passing between manager and client on --hint.

Met with HP, covered Manager aspects.  Next time: auroraagent

Mar 25:

Worked on finding a way to change SSID without restarting radios.  Short
story, command 'wifi' shuts down radios, reloads configuration from uci, then
restarts radios with new configuration.  Because of this, to change SSID,
radios must be restarted.  Thus, if SSID modification is requested, the whole 
slice might as well be restarted.

--> Wrote a slice_restart method on aurora agent, to give some flexibility
    about restarting slices either from the manager, or when a configuration
    goes wrong - last-known good configuration can be used.

Mar 26:

--> Continued implementation of slice_modify on agent
--> Fixed bug in tracking cumulative active time in metering

Mar 27:

--> Made documentation for python-auroraagent
--> Made progress on slice_modify on agent, manager
--> Added slice_modify to client and client shell

Mar 28:

Noticed that upon ap_slice_modify, slice gets created under default user 
instead of intended user.
--> Implemented a method in manager which tracks slice SSID upon status update
--> Made progress on slice_modify on both ap and manager

An issue exists in assigning unique MAC addresses for secondary slices on
agent when slices are restarted.  Slice MAC addresses are determined by using
the interface's base MAC address, modifying the leftmost byte to be equal to 
2 * the number of slices created.  Thus, the first slice will be assigned
    00:[tail of hw MAC]
the second:
    02:[tail of hw MAC]
the third
    04:[tail of hw MAC]
    
Restarting the second slice will result in it having a MAC address prefix
of 04, which results in the same as slice number three.
Somehow have to come up with a method that always guarantees unique MAC 
addresses under all circumstances.

Mar 31:

--> Finish ap-slice-modify on agent and manager

Walk through rabbitmq configuration with HP

Apr 1:

--> Implemented wnet-update-status in manager and client
--> Implemented a sync-config command to fetch the current configuration from
    the access point and use it to update manager's config_db
--> Changed tenant_id to string so names such as "Alice" and "Bob" can be used
--> Fixed some error handling in aurora_db for nonexistant wnets and slices
--> Changed wnet printing commands to use prettytable

Prepared for demo scenario

Apr 2:

--> Added wnet-modify-name command to have more control over wnets
--> Greatly improved dispatcher handling of downed channel

TODO: Work on unique MAC addressing on AP for each slice, see note Mar 28.
TODO: Powerpoint for presentation

Apr 3:

Powerpoint layout / talking points:

Virtualization - different types, tenancy
Purpose of each
Purpose of aurora - to make it easy for anybody to create a virtualized 
    wireless network
Where we are right now
Future steps - protocol based for better virtualization of radios, integration
    with SAVI (Tenant should have their own VM to direct traffic)
Flow of program - auroraclient, auroramanager, auroraagent and their purposes
Agent breakdown - slices created using different components
Configuration file for different slices
How messages are passed - AMQP
Demo scenario

Apr 4:

Creating a VM with SAVI.  Follow "How to get a VM.pdf", here:
https://drive.google.com/folderview?id=0B9jn6eidJZy2SFNVWlQyNS1XRm8&usp=sharing

Log in using openrc in devstack

    $ nova floating-ip-pool-list
    $ nova floating-ip-create ext_net
    $ nova flavor-list
    $ nova image-list
    $ nova keypair-list
    $ ssh-keygen
    $ nova keypair-add --pub-key .ssh/id_rsa.pub key2
    $ nova secgroup-list
    # Here the image is Ubuntu64.2.1
    $ nova boot --flavor m1.small --image da4c0bec-e11c-4390-b916-df7e972a1fc5 \
      --key-name key2 --security-groups aurora tenant1vm

    $ nova add-floating-ip --fixed-address 10.5.8.4 tenant1vm 132.206.206.139
    $ ssh ubuntu@132.206.206.139
    $ sudo passwd
pw: savimcgill

Setting up Tenant VM
Install DNSMasq
    $ sudo -s
    $ apt-get update; sudo apt-get upgrade
    $ apt-get install dnsmasq bridge-utils git make build-essential python-dev\
      supervisor
    $ git clone git://github.com/peymank/Capsulator.git
    $ ln -s /usr/bin/make /usr/bin/gmake
    $ cd Capsulator
    $ make
    $ ln -s ~/Capsulator/capsulator /usr/local/bin/capsulator

    $ brctl addbr brint
    $ ifconfig brint up 192.168.0.1/24
    # -t [external interface] -f [remote capsulator ip]
    # -vb [create virtual interface to receive traffic #<tag>
    $ capsulator -t eth0 -f 10.5.8.203 -vb tun0#0 &
    $ brctl addif brint tun0

Note: Capsulator interfaces will continue to exist even after the script has
      shut down.  You must remove them manually.
    $ ip link del tun0
    
    $ vi /etc/dnsmasq.conf
# Find and edit the following lines
----------/etc/dnsmasq.conf----------
interface=brint
dhcp-range=192.168.0.50,192.168.0.150,12h
dhcp-host=00:21:5d:22:97:8c,192.168.0.60

    $ sudo /etc/init.d/dnsmasq restart

Now set up IP masquerading (Routing) to allow internal machines internet access
External interface is eth0, internal interface is brint.
The script provided in python-auroratenant does this.  Place it on tenant 
VM and make it executable.
    $ chmod +x rc.firewall-iptables
    $ sudo sh rc.firewall-iptables
    # Now make sure the rules are applied every time the machine reboots
    $ sudo apt-get install iptables-persistent

If ever the rules change, aka adding a different subnet or internal interface,
run iptables-save to keep update the configuration
    $ iptables-save

TODO: Finish auto_capsulator script, configuration on tenant VM.
    
Apr 7:

Progress on auto_capsulator.  Wrote a script to do most of the work for the 
user.

Follow this procedure to set up a tenant vm which will automatically set up 
capsulator tunnels using capsulator "auto" attribute.


Do the necessary steps to get a tenant VM using nova, see Apr 4 notes until and
including 
    $ nova boot --flavor m1.small \
      --image da4c0bec-e11c-4390-b916-df7e972a1fc5 \
      --key-name <your-key (key2)> \
      --security-groups <active-secgroup (aurora)> \
      <vm-name (tenant1vm)
    $ nova add-floating-ip --fixed-address <fixed-ip (10.5.8.4)> \
      <vm-name (tenant1vm)> <floating-ip (132.206.206.139)>

Now copy the auroratenant files:
    $ scp python-auroratenant/* ubuntu@<floating-ip (132.206.206.139)>

SSH to the VM and run setup.py.
    $ ssh <floating-ip (132.206.206.139)>
    $ sudo bash setup.sh install
    
Let it do its thing.  When it is done, a screen will be launched with the
server listening for incoming capsulator tunnel requests.  There is probably 
a more elegant way of making the daemon, but screen makes it easy to configure.

Now, in the capsulator options, use auto for tunnel tag.

Apr 8:

--> Fixed bugs in auto capsulator option in manager.
--> Added many docstrings

TODO: Regenerate docstrings and debug if necessary.

Apr 9:

TODO:
Documentation
OpenHAL
Transfer capsulator to HP
OVS big picture to HP
    
Tip: Deleting many rabbitmq queues:
http://stackoverflow.com/questions/6742938/deleting-queues-in-rabbitmq

--> Changed the way manager sets up and manages its own reply queue    
--> Finished documentation in Dispatcher
--> Fixed dispatcher's queue declaration to have a set queue name

Apr 10:

Finished documentation for aurora manager.
Transferred auroratenant to HP
Started talking about Openflow

Apr 11:

Read about OpenHAL

From http://madwifi-project.org/wiki/About/OpenHAL

 On Fri, 26 Sep 2008 Atheros announced the release of legacy-HAL, an open 
 source version of the binary HAL, in order to help ath5k development 
 process so OpenHAL became obsolete. Later Sam Leffler also released his 
 open source version of HAL that we now use on MadWiFi and it's being used 
 on FreeBSD.

 On 25/07/2008 Atheros released ath9k a fully open-source driver for their 
 new 11n chips. 

Can be found on github:
    https://github.com/qca/qca-legacy-hal

Madwifi on github:
    https://github.com/mickflemm/madwifi-old-openhal

Linux networking 
    http://www.linuxfoundation.org/collaborate/workgroups/networking/networkoverview
    http://www.linuxfoundation.org/collaborate/workgroups/networking/linux-wireless-subsystem-80211-rami-rosen  
    http://ramirose.wix.com/ramirosen
    http://www.haifux.org/lectures/206/

Linux Wireless Slides:
    http://www.haifux.org/lectures/206/wirelessLec.pdf

ath5k/athk9k driver doesn't load firmware. (its fw is
burnt into an onchip ROM)

--> Fixed random MAC address generation in OpenWRT wifi

Apr 14:

ath5k linux source:
http://git.kernel.org/cgit/linux/kernel/git/linville/wireless-testing.git/tree/drivers/net/wireless/ath/ath5k

Have to consider how to handle both RX and TX requests, as each has their 
own procedures.


TX:
- Theory: https://docs.google.com/file/d/0Bws_ansZMTXcV3YxNkNjeDlYUFU/edit
    page 36,37

base.c:732:ath5k_txbuf_setup()
- Responsible for setting up the transmission of a frame, including hardware
    specific parameters.  One could define a handler for WARP in the call
    796:ah->ah_setup_tx_desc(), which is a callback for the specific network 
    card on which the transmission has been determined to happen.
    
- Addition of a function for handling transmission by WARP could somehow wrap a 
    frame and header in a data packet and pass it over ethernet or some other 
    communication link to the WARP board.  The WARP board would then be 
    responsible for transmitting the frame - would need more in-depth 
    understanding of how WARP processes requests to give a better suggestion.
    
- Would have to follow a similar structure as current implementations for AR5xxx
    do - provide a call and handle for a tasipklet similar to ath5k_tasklet_tx().
    
RX:
- Theory: https://docs.google.com/file/d/0Bws_ansZMTXcV3YxNkNjeDlYUFU/edit
    page 24,25
    
I'm not sure how WARP handles incoming packets, but assuming it will just output
raw frame data to its ethernet port, one could watch for incoming data packets 
from the WARP board on the machine running mac80211, translate data into an 
ath5k_hw struct, and call ath5k_schedule_rx().

base.c:2221:ath5k_schedule_rx()
- Will create a tasklet event, which will eventually call 
    base.c:1512:ath5k_tasklet_rx().  One would have to revise how 
    base.c:2933:ath5k_init() sets up the its hardware data - this could be 
    a lot of work.

And that's all folks!

2014
Author: Mike Kobierski